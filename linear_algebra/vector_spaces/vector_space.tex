%=======================================================[[Define parameter of document]]
\documentclass{article}
\pagestyle{empty}
\setlength{\paperwidth}{8.5in}
\setlength{\paperheight}{11in} 
\setlength{\topmargin}{-0.75in}
\setlength{\headsep}{0.00in} 
\setlength{\headheight}{0.00in}
\setlength{\evensidemargin}{-0.50in}
\setlength{\oddsidemargin}{-0.50in} 
\setlength{\textwidth}{7.50in}
\setlength{\textheight}{10in} 
\setlength{\voffset}{0.00in}
\setlength{\hoffset}{0.00in} 
\setlength{\marginparwidth}{0.00in}
\setlength{\marginparsep}{0.00in} 
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.0in}

%=======================================================[[Package]]
%\usepackage[dvipdf]{graphicx}
%\usepackage{amsfonts}
%\usepackage{mathptmx}
%\usepackage[scaled=.90]{helvet}
%\usepackage{courier} 
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
%\usepackage[T1]{fontenc}
\usepackage{linalgjh}
\usepackage{paralist}
\usepackage{verbatim}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,
    urlcolor=blue,
    citecolor=blue
}
\urlstyle{same}

%\usepackage[margin=0.5in]{geometry}

\usepackage{fancyhdr}
\usepackage{lastpage}
 
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\rfoot{Page \thepage \hspace{1pt} of \pageref*{LastPage}}

\def\Dash{\unskip\thinspace\textemdash\thinspace\ignorespaces\allowbreak}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{cor}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

\theoremstyle{example}
\newtheorem{example}{Example}[section]


%=======================================================[[Title page information]]
%=======================================================[[Document begins here]]
\begin{document}
\begin{center}
\begin{huge}
Introduction to Vector Spaces
\end{huge}
\end{center}
\tiny
\fbox{\parbox{\textwidth}{\scshape
Modified from \emph{Linear Algebra} by Jim Hefferon 
\texttt{\url{http://joshua.smcvt.edu/linearalgebra}} and
{A First Course in Linear Algebra} by Robert A. Beezer
\texttt{\url{http://linear.ups.edu/}} by Emilie Richer and Yann Lamontagne \texttt{\url{http://obeymath.org}}  (licensed under GNU Free Documentation License or the
Creative Commons Attribution-ShareAlike License.), \today.}}
\normalsize

\section*{Definition of Vector Space}
We shall study structures with two operations,
an addition and a scalar multiplication, that are subject to some
simple conditions.
We will reflect more on the conditions later
but on first reading notice how reasonable they are.
For instance, surely any operation that can be called an addition
(e.g., column vector addition, row vector addition, or
real number addition) will satisfy conditions (1) through~(5) below.

\vspace*{1ex}
\section{Definition and Examples}

\begin{definition}
\label{def:VecSpace}
%<*df:VectorSpace>
A \definend{vector space}\index{vector space!definition}
(over \( \Re \)) consists of a set \( V \) along with
two operations 
`+'\index{vector!sum}\index{sum!vector}\index{addition of vectors} 
and `\( \cdot \)'\index{scalar multiple!vector}\index{vector!scalar multiple} 
subject to the conditions
that for all vectors \( \vec{v},\vec{w},\vec{u}\in V \)
and all \definend{scalars}\index{scalar}
\( r,s\in\Re \):
% \begin{tfae}
\begin{compactenum} 
\item the set $V$ is closed under
  vector addition, that is, 
  \( \vec{v}+\vec{w}\in V \)
\item vector addition is commutative,
  \( \vec{v}+\vec{w}=\vec{w}+\vec{v} \) 
\item vector addition is associative,
  \( (\vec{v}+\vec{w})+\vec{u}=\vec{v}+(\vec{w}+\vec{u}) \)
\item there is a \definend{zero vector}\index{zero vector}
    \( \zero\in V \) such that
    \( \vec{v}+\zero=\vec{v}\, \) for all \( \vec{v}\in V\/ \)
\item each \( \vec{v}\in V \) has an
    \definend{additive inverse}\index{additive inverse}\index{inverse!additive}
    \( \vec{w}\in V \) such that \( \vec{w}+\vec{v}=\zero \)
\item  the set $V$ is closed under
    scalar multiplication, that is, 
   \( r\cdot\vec{v}\in V \)
\item addition of scalars distributes over scalar multiplication,
 \( (r+s)\cdot\vec{v}=r\cdot\vec{v}+s\cdot\vec{v} \)
\item scalar multiplication distributes over vector addition,
  \( r\cdot(\vec{v}+\vec{w})=r\cdot\vec{v}+r\cdot\vec{w} \)
\item ordinary multipication of scalars associates with 
  scalar multiplication, \( (rs)\cdot\vec{v} =r\cdot(s\cdot\vec{v}) \)
\item multiplication by the scalar~$1$ is the 
  identity operation, \( 1\cdot\vec{v}=\vec{v} \).
\end{compactenum}
% \end{tfae}  
%</df:VectorSpace>
\end{definition}

\begin{remark}
The definition involves two kinds of addition and two kinds of multiplication,
and so may at first seem confused.
For instance, in condition~(7)
the `$+$' on the left is addition of two real numbers
while the `$+$' on the right is addition of two vectors in
\( V\/ \).
These expressions aren't ambiguous because of context; for example,
\( r \) and \( s \)
are real numbers so `\( r+s \)' can only mean real number addition.
In the same way, item~(9)'s left side `$rs$' is ordinary real number 
multiplication, while its right side `$s\cdot\vec{v}$' is 
the scalar multipliction defined for this
vector space.
\end{remark}

The best way to understand the definition is to
go through the examples below and for each,
check all ten conditions.
Especially important are the \definend{closure}\index{vector space!closure}
conditions, (1) and~(6).
They specify that the addition and scalar multiplication operations
are always sensible\Dash they are defined for every pair of vectors 
and every scalar and vector,
and the result of the operation is a member of the set. 

\begin{example}  \label{ex:RealVecSpaces}
The set
\( \Re^2 \) is a vector space if the operations `\( + \)' and `\( \cdot \)'
have their usual meaning.
\begin{equation*}
  \colvec{x_1 \\ x_2}
  +
  \colvec{y_1 \\ y_2}
  =
  \colvec{x_1+y_1 \\ x_2+y_2}
  \qquad
  r\cdot
  \colvec{x_1 \\ x_2}
  =
  \colvec{rx_1 \\ rx_2}
\end{equation*}
\end{example}
 
\newpage
$ $
\newpage
 
\begin{example} 
This subset of \( \Re^3 \) that is a plane through the origin
\begin{equation*}
  P=\left\{ \colvec{x \\ y \\ z}  \Big|\; x+y+z=0\right\}
\end{equation*}
is a vector space if `+' and `\(\cdot\)' are interpreted in this way.
\begin{equation*}
  \colvec{x_1 \\ y_1 \\ z_1}
  +
  \colvec{x_2 \\ y_2 \\ z_2}
  =
  \colvec{x_1+x_2 \\ y_1+y_2 \\ z_1+z_2}
  \qquad
  r\cdot
  \colvec{x \\ y \\ z}
  =
  \colvec{rx \\ ry \\ rz}
\end{equation*}
\end{example}
\newpage

\begin{example} 
Let $V$ be the set of all pairs $(x,y)$ where $x, y \in \mathbb{R}$ 
and where addition and scalar multiplication is defined as:
\begin{equation*}
  (x,y)
  +
  (x',\;y')
  =
  (y+y',\;x+x')
  \qquad
  r\cdot(x,\;y)
  =
  (0,\;ry).
\end{equation*}
Is $V$ a vector space?
\end{example}
\newpage



\begin{example}  \label{ex:TrivSbspReFour}
The singleton set
\begin{equation*}
  \{ \vec{0} \}
\end{equation*}
is a vector space under the operations 
\begin{equation*}
  \vec{0}
  +
  \vec{0}
  =
  \vec{0}
  \qquad
  r\cdot\vec{0}
  =
  \vec{0}.
\end{equation*}
\end{example}
\begin{definition} \label{df:TrivialVectorSpace}
%<*df:TrivialVectorSpace>
A one-element vector space is a \definend{trivial}\index{vector space!trivial}%
\index{trivial space}
space.
%</df:TrivialVectorSpace>
\end{definition}

\begin{example} \label{ex:PolySpaceThree}
Consider
\( \polyspace_3=\set{a_0+a_1x+a_2x^2+a_3x^3\suchthat a_0,\ldots,a_3\in\Re} \),
the set of polynomials of degree three or less
(in this book, we'll take constant polynomials, 
including the zero polynomial, to be of degree zero).
It is a vector space under the operations
\begin{multline*}
   (a_0+a_1x+a_2x^2+a_3x^3)+(b_0+b_1x+b_2x^2+b_3x^3)
     =(a_0+b_0)+(a_1+b_1)x+(a_2+b_2)x^2+(a_3+b_3)x^3
\end{multline*}
and
\begin{equation*}
   r\cdot(a_0+a_1x+a_2x^2+a_3x^3)=
     (ra_0)+(ra_1)x+(ra_2)x^2+(ra_3)x^3
\end{equation*}
(the verification is easy).
\end{example}
\vspace{4in}
\begin{example} \label{ex:MatSpaceTwoByTwo}
The set \( \matspace_{\nbym{2}{2}} \) of \( \nbym{2}{2} \) matrices with
real number entries is a vector space under the natural 
entry-by-entry operations.
\begin{equation*}
  \begin{mat}
    a  &b \\
    c  &d
  \end{mat}
  +
  \begin{mat}
    w  &x \\
    y  &z
  \end{mat}
  =
  \begin{mat}
    a+w  &b+x \\
    c+y  &d+z
  \end{mat}
  \qquad
  r\cdot
  \begin{mat}
    a  &b \\
    c  &d
  \end{mat}
  =
  \begin{mat}
    ra  &rb \\
    rc  &rd
  \end{mat}
\end{equation*}
\end{example}
\newpage
$ $
\newpage

\begin{example} \label{ex:PolysOfAllFiniteDegrees}
The set of polynomials with real coefficients
\begin{equation*}
 \set{ a_0+a_1x+\cdots+a_nx^n\suchthat n\in\N
    \text{ and } a_0,\ldots,a_n\in\Re} 
\end{equation*}
makes a vector space when given the natural `$+$' 
\begin{equation*}
  (a_0+a_1x+\cdots+a_nx^n)+(b_0+b_1x+\cdots+b_nx^n)  
     =(a_0+b_0)+(a_1+b_1)x+\cdots +(a_n+b_n)x^n
\end{equation*}
and `$\cdot$'
\begin{equation*}
  r\cdot (a_0+a_1x+\ldots+ a_nx^n)
   =
  (ra_0)+(ra_1)x+\ldots +(ra_n)x^n
\end{equation*}
\end{example}
\vspace{5in}

\begin{definition}
$\Re^\infty$ is the vector space of infinite sequence of 
real numbers
\[
\Re^\infty=\{(a_0, a_1, a_2, \ldots, a_n, \ldots ) \;|\; a_i\in \Re\}
\]
with the following operations
\[
\vec{u}+\vec{v} = (u_0, u_1, u_2, \ldots, u_n, \ldots ) + (v_0, v_1, v_2, \ldots, v_n, \ldots ) = (u_0+v_0, u_1+v_1, u_2+v_2, \ldots, u_n+v_n, \ldots )
\]
and
\[
r\cdot(u_0, u_1, u_2, \ldots, u_n, \ldots ) = (ru_0, ru_1, ru_2, \ldots, ru_n, \ldots ).
\] 
\end{definition}
\newpage

\begin{example}  \label{ex:RealValuedFcns}
Is set $V=\Re^2$ under the following operations
\begin{equation*}
  \vec{u}+\vec{v}=(u_1, u_2)+(v_1, v_2) = (u_1+v_1, u_2+v_2)
  \qquad
  r\cdot\vec{u}=r\cdot(u_1, u_2) = (ru_1,0)
\end{equation*}
a vector space?
\end{example}
\vspace{3in}


\begin{example}  \label{ex:RealValuedFcns}
The set
\( \set{f\suchthat \map{f}{\Re}{\Re} } \)
of all real-valued functions of one real variable
is a vector space under these
\begin{equation*}
  (f_1+f_2)\,(x)=f_1(x)+f_2(x)
  \qquad
  (r\cdot f)\,(x)=r\,f(x)
\end{equation*}
\end{example}
\newpage

\begin{example}
The set
$V=\{(x_1,\,x_2)\;|\;x_1,\,x_2\in\Re\}$.
of all real valued ordered pair is a vector space under these
\begin{equation*}
  (x_1,\,x_2)+(y_1,\,y_2)=(x_1+y_1+1,\,x_2+y_2+1).
  \qquad
  r\cdot(x_1,\,x_2)=(r x_1+r-1,\,r x_2+r-1).
\end{equation*}
\end{example}
\newpage

\begin{theorem} \label{lm:ElementaryPropertiesOfVectorSpaces}
%<*lm:ElementaryPropertiesOfVectorSpaces>
In any vector space \( V \), 
for any \( \vec{v}\in V \) and \( r\in\Re \), we have\\
(1)~\( 0\cdot\vec{v}=\zero \), \\
(2)~\( (-1\cdot\vec{v})+\vec{v}=\zero \), \\
(3)~\( r\cdot\zero=\zero \), and\\
(4)~if \(r\cdot\vec{v}=\zero \) then \(\vec{v}=\zero \) or \(r=0\).
%</lm:ElementaryPropertiesOfVectorSpaces>
\end{theorem}
\newpage
%\mbox{ } 
%\newpage
\section{Subspaces and Spanning Sets}
We saw that the plane through the origin is a planar subset of $\Re^3$. 
There, the vector space $\Re^3$ contains inside it another vector space, the plane.

\begin{definition} 
For any vector space,
a \definend{subspace} is a subset that is itself a vector space,
under the inherited operations.
\end{definition}

\begin{example} 
\begin{equation*}
  P=\set{\colvec{x \\ y \\ z}\suchthat x+y+z=0}
\end{equation*}
is a subspace of \( \Re^3 \).
As required by the definition 
the plane's operations are inherited from the larger space,
that is,
vectors add in $P$ as they add in $\Re^3$
\begin{equation*}
   \colvec{x_1 \\ y_1 \\ z_1}+\colvec{x_2 \\ y_2 \\ z_2}
   =\colvec{x_1+x_2 \\ y_1+y_2 \\ z_1+z_2}
\end{equation*}
and scalar multiplication is also the same as in $\Re^3$.
To show that $P$ is a subspace we need only note that it is a subset and then
verify that it is a space.
We have already checked that $P$ satisfies the conditions in the definition of a 
vector space.
\end{example}

\begin{example}   \label{ex:SubspacesRTwo}
The \( x \)-axis in \( \Re^2 \) 
is a subspace, where
the addition and scalar multiplication operations are 
the inherited ones.
\begin{equation*}
  \colvec{x_1 \\ 0}
    +
  \colvec{x_2 \\ 0}
    =
  \colvec{x_1+x_2 \\ 0}
  \qquad
  r\cdot\colvec{x \\ 0}
  =\colvec{rx \\ 0}
\end{equation*}
As in the prior example, to verify directly from the definition 
that this is a subspace we simply check that it is a
subset and then check that it satisfies
the conditions in definition of a vector space.
For instance the two closure conditions are 
satisfied: adding two vectors with a second component of zero results
in a vector with a second component of zero and multiplying a 
scalar times a vector with a second component of zero 
results in a vector with a second component of zero.
\end{example}

\begin{example}
Another subspace of $\Re^2$ is 
its trivial subspace.
\begin{equation*}
  \left\{\colvec[r]{0 \\ 0}\right\}
\end{equation*}
\end{example}

%<*ProperSubspace>
Any vector space has a trivial subspace \( \set{\zero\,} \).
At the opposite extreme, any vector space has itself for a subspace.
%</ProperSubspace>

\begin{note}
Subspaces of $\Re^2$ are: $\Re^2$, lines through the origin, trivial subspace.
\end{note}

\begin{example}  \label{ex:LinSubspPolyThree}
Vector spaces that are not $\Re^n$'s also have subspaces.
The space of cubic polynomials\\
\( \set{a+bx+cx^2+dx^3\suchthat a,b,c,d\in\Re} \) 
has a subspace comprised of all linear polynomials
\( \set{m+nx\suchthat m,n\in\Re} \).
\end{example}

\begin{example}
Another example of a subspace that is not a subset of an $\Re^n$ 
followed the definition of a vector space.
The space of all real-valued functions of one real variable 
\( \set{f\suchthat \map{f}{\Re}{\Re} } \) has the subspace of functions satisfying
the restriction $(d^2\,f/dx^2)+f=0$.
\end{example}

\begin{example} \label{ex:OperNotInherit}
The definition requires that the 
addition and scalar multiplication operations
must be the ones inherited from the larger space.
The set \( S=\set{1} \) is a subset of \( \Re^1 \).
And, under the operations $1+1=1$ and  $r\cdot 1=1$
the set $S$ is a vector space, specifically, a trivial space.
However, $S$ is not a subspace of \( \Re^1 \) because those aren't the
inherited operations, since of course \( \Re^1 \) has \( 1+1=2 \).
\end{example}

\begin{example}  \label{cex:RPlusNotSubSp}
Being vector spaces themselves, subspaces must satisfy the closure
conditions.
The set \( \Re^+ \) is not a subspace of the vector space \( \Re^1 \)
because with the inherited operations it is not closed under scalar
multiplication: if \( \vec{v}=1 \) then \( -1\cdot\vec{v}\not\in\Re^+ \).
\end{example}

The only way that a subset can fail to be a subspace, 
if it is nonempty and uses the inherited operations,
is if it isn't closed.

\begin{theorem}[Subspace Test]     \label{th:SubspIffClosed} \index{subspace!closed}
%<*lm:SubspIffClosed>
For a nonempty subset $W$ of a vector space $V$, under the inherited 
operations is a vector space if and only if
\begin{itemize}
  \item[Closed under addition:] For all $\vec{u}, \vec{v} \in W$, $\vec{u}+\vec{v}\in W$.
  \item[Closed under scalar multiplication:] For all $r\in\Re$ and all $\vec{u}\in W$, $k\vec{u}\in W$.
\end{itemize}
%</lm:SubspIffClosed>
\end{theorem}
\newpage
\mbox{} 
\vspace{5in}
\begin{remark}
$\Re^n$ for any $n\in\mathbb{N}$ is a vector space with the usual vector addition and scalar multiplication.
\end{remark}
\begin{example}
Determine which subsets are a subspace of $\Re^3$: $W_1=\left\{(x,0,y)\; |\; x,y\in\Re\right\}$, $W_2=\left\{(x,1,z)\; |\; x,z\in\Re\right\}$.
\end{example}
\vspace{4in}


\begin{note}
Subspaces of $\Re^3$ are: $\Re^3$, planes through the origin, lines through the origin, trivial subspace.
\end{note}
\newpage
\begin{remark}
$\matspace_{\nbyn{n}}$ for any $n\in\mathbb{N}$ is a vector space with the usual matrix addition and scalar matrix multiplication.
\end{remark}
\begin{example} \label{ex:ParamSubspace}
Show that $L$ is a subspace of the \( \nbyn{2} \) matrices $\matspace_{\nbyn{2}}$.
\begin{equation*}
  L=\left\{\begin{mat}
         a  &0  \\
         b  &c
       \end{mat}
       \suchthat a+b+c=0\right\}
\end{equation*}
\end{example}
\vspace{4in}

\begin{remark}
$P_n = \{ a_0+a_1x+a_2x^2+\cdots +a_nx^n\; |\; a_i\in\Re\}$ for any $n\in\mathbb{N}$ is a vector space with the usual polynomial addition and scalar polynomial multiplication.
\end{remark}
\begin{example}
Determine which subsets are a subspace of $P_3$: 
\[
W_1=\left\{p(x)\; |\; p(x)\in P_3\text{ and } \int_0^1 p(x)\;dx=1\right\},\;\;\;\; W_2=\left\{p(x)\; |\; p(x)\in P_3\text{ and } p'(\pi)=0\right\}
\]
\end{example}
\newpage

\begin{theorem}
If $A\mathbf{x}=\mathbf{0}$ is a homogenous linear system of $m$ equations in $n$ unknowns, then 
the set of \definend{solution vectors} is a subspace of $\Re^n$.
\end{theorem}
\vspace{4in}

\begin{example}
Express the subspace $W=\left\{\mathbf{x}\;|\;A\mathbf{x}=\mathbf{0}\text{ and }\mathbf{x}\in\Re^3\right\}$ of $\Re^3$ as a parametric equation where
\[
A=\begin{bmatrix}
1 & -1 & 0\\
2 & 1 & 1\\
-1 & 4 & 1
\end{bmatrix}
\]
\end{example}
\newpage


\begin{definition}
A vector $\vec{w}$ is a \definend{linear combination} of a set 
$S = \left\{ \vec{s}_1, \vec{s}_2, \ldots, \vec{s}_n\right\}$ if it 
can be expressed in the form
\[
\vec{w} = c_1\vec{s}_1+c_2\vec{s}_2+\cdots+c_n\vec{s}_n
\]
where $c_i\in\Re$.
\end{definition}

\begin{example}
Any vector $(a, b, c)\in\Re^3$ is expressible as a linear combination of 
the standard basis vectors
\[
(a, b, c) = a\vec{i}+b\vec{j}+c\vec{k}
\]
\end{example}

\begin{example}
Show that $\vec{w}=(3, -4, 2)$ is a linear combination of $\vec{u}=(4, -3, 3)$ and 
$\vec{v}=(1, 1, 1)$
\end{example}
\vspace{3in}

\begin{example}
Determine if $p(x)=2-1x$ is a linear combination of $p_1(x)=2+x$ and $p_2(x)=4+2x$.
\end{example}
\vspace{3in}

\begin{example}
Determine if $X$ is a linear combination of $A$, $B$, $C$ where
\[
X =
\begin{bmatrix}
2 & -1\\
3 & 1
\end{bmatrix},\;\;\;
A =
\begin{bmatrix}
2 & -1\\
3 & 0
\end{bmatrix},\;\;\;
B =
\begin{bmatrix}
1 & 2\\
3 & -1
\end{bmatrix},\;\;\;
C =
\begin{bmatrix}
-4 & -3\\
-9 & 3
\end{bmatrix}
\] 
\end{example}
\newpage
\mbox{}
\vspace{3in}
\begin{definition} \label{df:Span}
%<*df:Span>
The \definend{span} of a nonempty subset \( S \) of a
vector space is the set of all linear combinations of vectors from \( S \).
\begin{equation*}
  \mbox{span}(S) =\{ c_1\vec{s}_1+\cdots+c_n\vec{s}_n
            \suchthat c_1,\ldots, c_n\in\Re
            \text{\ and\ } \vec{s}_1,\ldots,\vec{s}_n\in S \}
\end{equation*}
The span of the empty subset of a vector space is its trivial subspace.
%</df:Span>
\end{definition}

\begin{theorem}   \label{le:SpanIsASubsp}
%<*lm:SpanIsASubsp>
In a vector space, the span of any subset is a subspace.  In addition, the 
span of a subset of a vector space is the smallest subspace containing all 
vectors of the subset.
%</lm:SpanIsASubsp>
\end{theorem}
\newpage

\begin{example}
Let $W=\mbox{span}\left\{\vec{u}, \vec{v} \right\}$ where $\vec{u}=(1, 0, 0)$ 
and $\vec{v}=(0, 1, 0)$.  Is $(1, 1, 1)$ in $W$? What about $(2, 3, 0)$?
\end{example}
\vspace{2.5in}

\begin{example}
Express the subspace $W=\left\{\mathbf{x}\;|\;A\mathbf{x}=\mathbf{0}\text{ and }\mathbf{x}\in\Re^3\right\}$ of $\Re^3$ as a span of a set of vectors where
\[
A=\begin{bmatrix}
1 & -1 & 1\\
2 & -2 & 2\\
-1 & 1 & -1
\end{bmatrix}
\]
\end{example}
\newpage

\begin{example}
Determine whether $S=\left\{(2, 1, 0),\; (-1, 3, 1),\; (1, 1, 1)\right\}$ spans $\Re^3$.
\end{example}
\vspace{5in}

\begin{example}
Determine whether $S=\left\{1+x+x^2,\; 1-x^2\right\}$ spans $P_2$.
\end{example}
\newpage
\begin{example}
Find the conditions on the coefficient of $p(x)=a_0+a_1x+a_2x^2$ such that $p(x)\in \mbox{span}(\{1+x+x^2,\; 1+2x+3x^2\})$
\end{example}
\vspace{5in}
\begin{theorem}
Let $S$ and $S'$ be subsets of a vector space $V$. If every vector in $S$ is expressible 
as a linear combination of the vectors in $S'$ then $\mbox{span}(S)$ is a subspace of $\mbox{span}(S')$. 
If in addition every vector of $S'$ is expressible 
as a linear combination of the vectors in $S$ then $\mbox{span}(S)=\mbox{span}(S')$.
\end{theorem}

\begin{example}
Let $S=\left\{M_1, M_2 \right\}$ and $S'=\left\{M_3, M_4\right\}$ where
\[
M_1 =
\begin{bmatrix}
2 & -1\\
3 & 0
\end{bmatrix},\;\;\;
M_2 =
\begin{bmatrix}
0 & 1\\
1 & 0
\end{bmatrix},\;\;\;
M_3 =
\begin{bmatrix}
4 & -1\\
7 & 0
\end{bmatrix},\;\;\;
M_4 =
\begin{bmatrix}
0 & 2\\
2 & 0
\end{bmatrix}
\] 
Is $\mbox{span}(S)=\mbox{span}(S')$?
\end{example}
\newpage
\begin{example}  \label{ex:SubspRThree}
The picture below shows the subspaces of \( \Re^3 \) that we now know of, the 
trivial subspace, the lines through the origin,
the planes through the origin, and the whole space
(of course, the picture shows only a few of the infinitely many subspaces). 
In the next section we will prove that $\Re^3$ has no other
type of subspaces, so in fact this picture shows them all.

That picture describes the subspaces 
as spans of sets with a minimal number of members.
Note that the subspaces 
fall naturally into levels\Dash planes on one level, 
lines on another,
etc.\Dash according to how many vectors are in the minimal-sized
spanning set.
\begin{center}
  \setlength{\unitlength}{4pt}
  \begin{picture}(75,38)(0,-2) %subspaces of R-three
      \thinlines
      \put(45,31){\makebox(0,0)[bl]{
                        \scriptsize \( %\Re^3=
                                   \set{x\colvec[r]{1 \\ 0 \\ 0}
                                              +y\colvec[r]{0 \\ 1 \\ 0}
                                              +z\colvec[r]{0 \\ 0 \\ 1}} \)} }
    %Next the dimension two subspaces
      \put(43,31){\line(-4,-1){25} } % connects R3 to 2,a
      %set 2,a:
      \put(0,22){\makebox(0,0)[l]{\scriptsize\( \set{x\colvec[r]{1 \\ 0 \\ 0}
                                                 +y\colvec[r]{0 \\ 1 \\ 0} }\) }}
      \put(48,29){\line(-3,-1){12} } % connects R3 to 2,b
      %set 2,b:
      \put(20,22){\makebox(0,0)[l]{\scriptsize\( \set{x\colvec[r]{1 \\ 0 \\ 0}
                                                 +z\colvec[r]{0 \\ 0 \\ 1} }\) }}
      \put(53,29){\line(-1,-1){3}} % connects R3 to 2,c
      %set 2,c:
      \put(40,22){\makebox(0,0)[l]{\scriptsize\( \set{x\colvec[r]{1 \\ 1 \\ 0}
                                                 +z\colvec[r]{0 \\ 0 \\ 1} }\) }}
      \put(60,22){\makebox(0,0)[l]{$\cdots$} }
    %Next the dimension one subspaces
      \put(7,18){\line(-1,-4){1} } % connects 2,a to 1,a
      \put(22,18){\line(-3,-1){13} } % connects 2,c to 1,a
      %set 1,a:
      \put(0,10){\makebox(0,0)[l]{\scriptsize\( \set{x\colvec[r]{1 \\ 0 \\ 0}} \)} }
      \put(12,18){\line(1,-2){2} } % connects 2,a to 1,b
      %set 1,b:
      \put(12,10){\makebox(0,0)[l]{\scriptsize\( \set{y\colvec[r]{0 \\ 1 \\ 0}} \)} }
      \put(14,18){\line(2,-1){10} } % connects 2,a to 1,c
      %set 1,c:
      \put(24,10){\makebox(0,0)[l]{\scriptsize\( \set{y\colvec[r]{2 \\ 1 \\ 0}} \)} }
      \put(46,18){\line(-1,-1){3.25} } %connects 2,c to 1,d
      %set 1,d:
      \put(36,10){\makebox(0,0)[l]{\scriptsize\( \set{y\colvec[r]{1 \\ 1 \\ 1}} \)} }
      \put(48,10){\makebox(0,0)[l]{$\cdots$} }
    %Finally, the trivial subspace.
      \put(9,7.5){\line(4,-1){30} } %connects 1,a to trivial
      \put(18.9,7.7){\line(3,-1){20} } %connects 1,b to trivial
      \put(30.4,6.8){\line(2,-1){10} } %connects 1,c to trivial
      \put(41,6){\line(1,-2){1.5} } %connects 1,d to trivial
      \put(45,0){\makebox(0,0){\scriptsize\( \set{\colvec[r]{0 \\ 0 \\ 0} } \)} }
  \end{picture}
\end{center}
\noindent The line segments between levels connect subspaces with 
their superspaces. 
\end{example}
\newpage
%\mbox{ }
%\newpage

\section{Linear Independence}

\begin{definition}\label{def:LinInd}
%<*df:LinInd>
A nonempty subset $S = \left\{ \vec{s}_1,\; \vec{s}_2,\; \ldots,\; \vec{s}_n\right\}$ of a vector space is
\definend{linearly independent}
if 
\[
\vec{0} = c_1\vec{s}_1+c_2\vec{s}_2+\cdots+c_n\vec{s}_n
\]
only has the \definend{trivial solution}, that is, $c_1=c_2=\ldots =c_n=0$. Otherwise it is \definend{linearly dependent}.
%</df:LinInd>
\end{definition}

\begin{example}
Determine if $S=\{\vec{u},\; \vec{v},\; \vec{w}\}$ where
\[
\vec{u}=(2, 1, 3),\;\;\; \vec{v}=(1, 3, 1),\;\;\; \vec{w}=(3, 4, 4)
\] 
is linearly independent.
\end{example}
\vspace{1.5in}

\begin{example}
Determine if $S=\{M_1, M_2, M_3\}$ where
\[
M_1 =
\begin{bmatrix}
1 & 0\\
2 & 0
\end{bmatrix},\;\;\;
M_2 =
\begin{bmatrix}
2 & 1\\
3 & 1
\end{bmatrix},\;\;\;
M_3 =
\begin{bmatrix}
-1 & -3\\
-3 & 4
\end{bmatrix}
\]
is linearly independent.
\end{example}
\newpage

\begin{example}
Suppose $S=\{\vec{v}_1,\; \vec{v}_2,\; \vec{v}_3\}$ is linearly independent.  Are the vectors
\[
\vec{v}_1-\vec{v}_2,\; \vec{v}_3+\vec{v}_2,\; \vec{v}_1-\vec{v}_3
\]
linearly independent?
\end{example}
\vspace{5in}


\begin{theorem}
The polynomials
\[
1,\;x,\;x^2,\;\ldots,\;x^n
\]
form a linearly independent set.
\end{theorem}
\newpage

\begin{example}
Determine if $S=\{p_1(x), p_2(x), p_3(x)\}$ where
\[
p_1(x)=1-2x+x^2,\;\;\; p_2(x)=3+2x^2,\;\;\; p_3(x)=1+x+x^2
\] 
is linearly independent.
\end{example}
\vspace{3in}


\begin{theorem} A subset \( S=\set{\vec{s}_1,\vec{s}_2,\dots,\vec{s}_n} \) of a vector space
is linearly dependent if and only if some \( \vec{s}_i \)
is a linear combination of the vectors $S-\{\vec{s}_i\}$.
\end{theorem}
\newpage
\begin{cor} It follows, that subset \( S=\set{\vec{s}_1,\vec{s}_2,\dots,\vec{s}_n} \) of a vector space
is linearly independent if and only if no \( \vec{s}_i \)
is a linear combination of the vectors $S-\{\vec{s}_i\}$.
\end{cor}


\begin{example} 
What can be said about the linear independence of the following set $S = \left\{ \vec{s}_1,\; \vec{s}_2,\; \ldots,\; \vec{s}_n,\; \vec{0}\right\}$?
\end{example}
\vspace{2in}

\begin{example} 
What can be said about the linear independence of the following set $S = \left\{ \vec{s}_1 \right\}$?
\end{example}
\vspace{2in}

\begin{example} 
What can be said about the linear independence of the following set $S = \left\{ \vec{s}_1,\; \vec{s}_2 \right\}$?
\end{example}
\vspace{2in}


\begin{note}
Geometric Interpretation:\\
Two vectors in $\Re^2$ and $\Re^3$ are linearly independent if and only if the vectors do not lie on the same line
(when their initial points are at the origin).\\

Three vectors in $\Re^3$ are linearly independent if they do not lie on the same plane (when their initial points are at the origin).
\end{note}
\newpage
%\mbox{ }
%\newpage

\section{Coordinates and Basis}

\begin{definition}
A \definend{basis} $B$
for a vector space $V$ is a sequence of vectors $\{\vec{b}_1,\;\vec{b}_2,\;\ldots,\;\vec{b}_n\}$ that is linearly independent 
and that spans the vector space $V$.
\end{definition}
\vspace{1.5in}

\begin{definition}
For $\Re^2$ the \definend{standard} (or \definend{natural}) basis is $\{\vec{i},\; \vec{j}\}$.\\
For $\Re^3$ the \definend{standard} (or \definend{natural}) basis is $\{\vec{i},\; \vec{j},\; \vec{k}\}$.\\
For $\Re^n$ the \definend{standard} (or \definend{natural}) basis is
$\{ \vec{e}_1=(1,\;0,\;0,\;\ldots,\;0),\; \vec{e}_2=(0,\; 1,\; 0,\;\ldots, 0),\; \vec{e}_3=(0,\; 0,\; 1,\;\ldots, 0), \ldots, \vec{e}_n=(0,\; 0,\; 0,\;\ldots, 1)\}$
\end{definition}

\begin{example}
Determine if $B=\{\vec{v}_1,\; \vec{v}_2, \vec{v}_3\}$ where
\[
\vec{v}_1 = (1, 2, 1),\;\;\; \vec{v}_2 = (2, 9, 0),\;\;\; \vec{v}_3=(3, 3, 4)
\]
is a basis for $\Re^3$
\end{example}
\newpage


\begin{theorem}
If $B=\{\vec{b}_1,\; \vec{b}_2,\;\ldots,\; \vec{b}_n\}$ is linearly independent then $B$ is a basis for $V=\mbox{span}(B)$.
\end{theorem}
\vspace{2in}

\begin{example}  
Determine if $B=\{\cos^2x,\; \sin^2x,\; \cos2x\}$ is a basis for the vector space  $V = \mbox{span}\{ B\}$.
\end{example}
\vspace{2in}

\begin{definition}
For $P_n$ the \definend{standard} (or \definend{natural}) basis is $\{1,\; x,\; x^2,\;\ldots,\;x^n\}$.
\end{definition}
\begin{example}
The space of finite-degree polynomials 
$\set{ a_0+a_1x+\cdots+a_nx^n\suchthat n\in\N \text{ and } a_0,\ldots,a_n\in\Re}$ 
has a basis with infinitely many vectors $\{1,\;x\;,x^2\;,\ldots\}$.
\end{example}
\begin{example}
Determine if $B=\{1+x+x^2,\; x+x^2,\; x^2\}$ is a basis for the vector space $P_2$. 
\end{example}

\newpage

\begin{definition}
For \( \matspace_{\nbym{2}{2}} \) the \definend{standard} (or \definend{natural}) basis is 
\[
\left\{
\begin{bmatrix}
1 & 0\\
0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 1\\
0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0\\
1 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0\\
0 & 1
\end{bmatrix}
\right\}
\]
For \( \matspace_{\nbym{3}{3}} \) the \definend{standard} (or \definend{natural}) basis is 
\[
\left\{
\begin{bmatrix}
1 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 1 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 1\\
0 & 0 & 0\\
0 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 0\\
1 & 0 & 0\\
0 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 1\\
0 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
1 & 0 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 1 & 0
\end{bmatrix},\;
\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 1
\end{bmatrix}
\right\}
\]
For \( \matspace_{\nbym{n}{n}} \) the \definend{standard} (or \definend{natural}) basis has $n^2$ vectors.
\end{definition}

\begin{example}
Find a basis for the vector space $V = \left\{A\; | \; A\in \matspace_{\nbym{2}{2}} \text{ and } A^T=A\right\}$ 
with the usual matrix addition and matrix scalar multiplication. 
\end{example}
\newpage

\begin{theorem}[Uniqueness of Basis Representation] 
In any vector space $V$, a subset $B$ is a basis
if and only if each vector in the vector space $V$ can be expressed as a linear combination of elements of the subset $B$ 
in one and only one way.
\end{theorem}
\vspace{8in}

\begin{definition} 
In a vector space with basis $B$
the \definend{coordinate vector of $\vec{v}$ relative to $B$} (or \definend{representation of \( \vec{v} \) with respect to \( B \)}) is a vector of the coefficients used to express $\vec{v}$ as a 
linear combination of the basis vectors:
\begin{equation*}
  \rep{\vec{v}}{B} = (\vec{v})_B = (c_1,\; c_2,\; \ldots,\; c_n )
\end{equation*}
where
\( B=\{\vec{b}_1,\; \vec{b}_2,\; \dots,\;\vec{b}_n\} \) and 
\( \vec{v}=c_1\vec{b}_1 + c_2\vec{b}_2 + \ldots + c_n\vec{b}_n \).
\end{definition}

\begin{remark}
The definition of the basis requires that a basis be a sequence
because without that we couldn't write these coordinates in a fixed order. 
\end{remark}

\begin{example}
Find the coordinate vector of $\vec{v}=(3,4)$ relative to the basis 
$B=\{\vec{i},\;\vec{j}\}$.
\end{example}
\vspace{1in}

\begin{example}
Find the coordinate vector of $\vec{v}=(3,4)$ relative to the basis 
$B=\{\vec{b}_1,\;\vec{b}_2\}$ where
\[
\vec{b}_1=(2, -4)\;\;\;\vec{b}_2=(3, 2)
\]
\end{example}
\vspace{2in}
\begin{example}
Find a basis $B$ for the vector space $V = \left\{A\; | \; A\in \matspace_{\nbym{3}{3}} \text{ and } A^T=-A\right\}$ 
with the usual matrix addition and matrix scalar multiplication. 
Find the coordinate vector of
\[
\begin{bmatrix}
0 & 1 & -2\\
-1 & 0 & -3\\
2 & 3 & 0
\end{bmatrix}
\]
relative to the basis $B$.

\end{example}
\newpage
\[
\]
\vspace{2in}
\begin{example}
Let $W=\{p(x)=a_0+a_1x+a_2x^2\; |\; p'(1)=0 \}$ be a subspace of $P_2$.
Find a basis $B$ for $W$.
Find the coordinate vector of $p(x)=-4-x+\frac{1}{2}x^2$ relative to the basis $B$.
\end{example}
\newpage
%\mbox{ }
%\newpage

\section{Dimension}

The previous subsection defines a basis of a vector space and
shows that a space can have many different bases.
So we cannot talk about ``the'' basis for a vector space.
True, some vector spaces have bases that strike us as more natural
than others.  We cannot, in general, associate with a space any single basis that
best describes it.

We can however find something about the bases that
is uniquely associated with the space.
This subsection shows that 
any two bases for a space have the same number of elements.
So with each space we can associate a number, 
the number of vectors in any of its bases.

Before we start, we first
limit our attention to spaces where at least one basis has only finitely
many members.

\begin{definition}
A vector space is \definend{finite-dimensional}
if it has a basis with only finitely many vectors.
\end{definition}

\noindent One space that is not finite-dimensional is $\Re^\infty$
this space is not spanned by any finite subset.

\begin{lemma}[Exchange Lemma] \label{lm:ExchangeLemma}
Assume that 
\( B= \{\vec{b}_1,\; \vec{b}_2,\;\dots,\;\vec{b}_n\} \) is a basis for a
vector space, and that for the vector \( \vec{v} \)
the relationship \( \vec{v}=\lincombo{c}{\vec{b}} \)
has \( c_i\neq 0 \).
Then exchanging \( \vec{b}_i \) for \( \vec{v} \) yields another
basis for the space.
\end{lemma}
\vspace{4.5in}

\begin{theorem}
In any finite-dimensional vector space, all 
bases have the same number of elements.
\end{theorem}

\begin{definition}  \label{df:Dimension}
The \definend{dimension} of a vector space is the number of vectors in any of its bases.
\end{definition}

\begin{example}
Any basis for \( \Re^n \) has \( n \) vectors since the standard basis 
\[
\{ \vec{e}_1=(1,\;0,\;0,\;\ldots,\;0),\; \vec{e}_2=(0,\; 1,\; 0,\;\ldots, 0),\; \vec{e}_3=(0,\; 0,\; 1,\;\ldots, 0), \ldots, \vec{e}_n=(0,\; 0,\; 0,\;\ldots, 1)\}
\]
has \( n \) vectors.
Thus, this definition of `dimension' generalizes the most familiar use of 
term, that $\Re^n$ is $n$-dimensional.
\end{example}

\begin{example}
The space \( P_n \) of polynomials of degree at most $n$ 
has dimension \( n+1 \).
We can show this by exhibiting any basis\Dash $\{1,\;x,\;\dots,\;x^n\}$ 
comes to mind\Dash and counting its members.
\end{example}

\begin{example}
The space \( \matspace_{\nbym{n}{n}} \) of $n\times n$ matrices has dimension $n^2$ since it 
has standard basis of $n^2$ vectors as previously discussed.
\end{example}


\begin{example}
The space of functions 
$\set{a\cdot\cos\theta+b\cdot\sin\theta\suchthat a,b\in\Re}$  
of the real variable $\theta$ has dimension~$2$ since this space has the 
basis $\{\cos\theta,\sin\theta\}$.
\end{example}

\begin{example}
A trivial space is zero-dimensional since its basis is empty.
\end{example}
\newpage


\begin{example}
Find a basis and determine the dimension of the subspace of $\Re^5$ determined by 
the solution vectors of the following homogeneous system.
\[
\begin{array}{ccccccccccccc}
x_1 & - & 2x_2 & + & x_3 & - & 3x_4 & + & x_5  &  = & 0\\
-x_1 & - & x_2 &  &   & + & x_4  &  &  &  = & 0\\
-2x_1 & + & 3x_2 & + & x_3 &  &   & - & x_5  &  = & 0\\
\end{array}
\]
\end{example}
\vspace{4in}
\begin{cor}
No linearly independent set can have a size greater than the dimension of the
enclosing space.
\end{cor}
\begin{example}
Verify the above corrollary by showing that $S=\{1,\; 1+x,\; 1+x+x^2,\; x+x^2\}$ is
linearly dependent in its enclosing space $P_2$.
\end{example}
\newpage

\begin{cor} 
Any linearly independent set can be expanded to make a basis.
\end{cor}
\begin{example}
Expand the set  $S=\{(1,\;1,\;1,1,1)\}$ to make a basis of the subspace of $\Re^5$ defined by
$W=\{ (a,b,a,b,c)\;|\;a, b, c\in \Re\}$.
\end{example}
\vspace{4in}

\begin{cor} 
Any spanning set can be shrunk to a basis.
\end{cor}
\begin{example}
Shrink the set $S=\{M_1,\; M_2,\; M_3,\; M_4,\; M_5\}$ such that it becomes a basis for $\mbox{span}(S)$ where
\[
M_1 =
\begin{bmatrix}
1 & 0\\
-2 & 0
\end{bmatrix},\;\;\;
M_2 =
\begin{bmatrix}
2 & 1\\
3 & 1
\end{bmatrix},\;\;\;
M_3 =
\begin{bmatrix}
-1 & -3\\
4 & 3
\end{bmatrix},\;\;\;
M_4 =
\begin{bmatrix}
1 & 2\\
-5 & 4
\end{bmatrix},\;\;\;
M_5 =
\begin{bmatrix}
3 & -1\\
-6 & 5
\end{bmatrix}
\]
\end{example}
\newpage


\begin{cor}
In an \( n \)-dimensional space, a set composed of \( n \) vectors is linearly 
independent if and only if it spans the space.
\end{cor}

\begin{example}
Find a basis for $P_3$ containing the linearly independent set $S=\{1+x,\; 1+x^2\}$ 
\end{example}
\vspace{4in}

\begin{example}
Let 
\[
A=
\begin{bmatrix}
1 & 1\\
0 & 0
\end{bmatrix}
\]
and $V=\left\{X\; | \; X\in \matspace_{\nbym{2}{2}} \text{ and } AX=X\right\}$ 
Find a basis of $V$ containing $A$.  Find a basis of $V$ not containing $A$. What is the dimension of $V$.
\end{example}
\newpage
\mbox{ }
\newpage







\end{document}

